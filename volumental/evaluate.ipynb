{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scipy.misc import imread\n",
    "\n",
    "from util.config import load_config\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "cfg = load_config(\"evaluate_pose_cfg.yaml\")\n",
    "\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import utils\n",
    "\n",
    "reconstruction_repo_path = pathlib.Path.home() / 'dev/Reconstruction'\n",
    "key_point_regressor = utils.TFLiteKeyPointRegressor(reconstruction_repo_path / 'komb/resources/moby/point_regressor.tflite')\n",
    "\n",
    "dataset_path = pathlib.Path('/moby/datasets/deepercut/volumental/cropped')\n",
    "image_group_path = dataset_path / 'group_9'\n",
    "annotations_path = dataset_path / 'annotations'\n",
    "\n",
    "image_paths = list(image_group_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(image_paths)\n",
    "image_paths_to_plot = image_paths[:8]\n",
    "\n",
    "fig, axes = plt.subplots(len(image_paths_to_plot) // 4, 4, figsize=(40, 10 * len(image_paths_to_plot) // 4), squeeze=True)\n",
    "axes = itertools.chain(*axes)\n",
    "\n",
    "for image_path, ax in zip(image_paths_to_plot, axes):\n",
    "    image = imread(image_path, mode='RGB')\n",
    "\n",
    "    image_batch = data_to_input(image)\n",
    "\n",
    "    # Compute prediction with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, _ = predict.extract_cnn_output(outputs_np, cfg)\n",
    "\n",
    "    # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "    pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "    \n",
    "    keypoint_path = utils.keypoint_path_from_cropped_image_path(image_path)\n",
    "    try:\n",
    "        with open(keypoint_path) as keypoint_file:\n",
    "            keypoints = json.load(keypoint_file)\n",
    "    except FileNotFoundError:\n",
    "        print(json_path)\n",
    "        continue\n",
    "    keypoints = np.array([[coords[0], coords[1]] for keypoint, coords in keypoints.items()])\n",
    "    \n",
    "    mu = utils.predict_with_regressor(image, key_point_regressor)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.scatter(mu[:, 0], mu[:, 1], c='blue')\n",
    "    ax.scatter(pose[:,0], pose[:,1], c='orange')\n",
    "    ax.scatter(keypoints[:,0], keypoints[:,1], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, _ in zip(image_paths_to_plot, range(4)):\n",
    "    image = imread(image_path, mode='RGB')\n",
    "\n",
    "    image_batch = data_to_input(image)\n",
    "\n",
    "    # Compute prediction with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, _ = predict.extract_cnn_output(outputs_np, cfg)\n",
    "\n",
    "    # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "    pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "    \n",
    "    # Visualise\n",
    "    visualize.show_heatmaps(cfg, image, scmap, pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "path = pathlib.Path('/moby/datasets/real_feet_resized/Feet Annotation Batch 1 tagging results dwHQG4wrvC9MeWxTt/')\n",
    "\n",
    "df = pd.read_csv('/moby/datasets/real_feet_resized/Feet Annotation Batch 1 tagging results dwHQG4wrvC9MeWxTt/structure.csv')\n",
    "df['ImagePath'] = df[\"Filename\"].apply(lambda s: str(path /'images'/ s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "df_sampled = df[:20]\n",
    "\n",
    "fig, axes = plt.subplots(len(df_sampled) // 4, 4, figsize=(40, 10 * len(df_sampled) // 4), squeeze=True)\n",
    "axes = itertools.chain(*axes)\n",
    "padding=10\n",
    "for (index, row), ax in zip(df_sampled.iterrows(), axes):\n",
    "    image = imread(row['ImagePath'], mode='RGB')\n",
    "    image = image[row['Top']-padding:row['Top']+row['Height']+padding, row['Left']-padding:row['Left']+row['Width']+padding]\n",
    "    image_batch = data_to_input(image)\n",
    "\n",
    "    # Compute prediction with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, _ = predict.extract_cnn_output(outputs_np, cfg)\n",
    "\n",
    "    # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "    pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "    \n",
    "    mu = utils.predict_with_regressor(image, key_point_regressor)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.scatter(pose[:,0], pose[:,1], c='orange')    \n",
    "    ax.scatter(mu[:, 0], mu[:, 1], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, row), _ in zip(df_sampled.iterrows(), range(4)):\n",
    "    image = imread(row['ImagePath'], mode='RGB')\n",
    "    image = image[row['Top']-padding:row['Top']+row['Height']+padding, row['Left']-padding:row['Left']+row['Width']+padding]\n",
    "    image_batch = data_to_input(image)\n",
    "\n",
    "    # Compute prediction with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, _ = predict.extract_cnn_output(outputs_np, cfg)\n",
    "\n",
    "    # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "    pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "    \n",
    "    visualize.show_heatmaps(cfg, image, scmap, pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "deepercut_error_pixel = 0\n",
    "regressor_error_pixel = 0\n",
    "deepercut_error_relative = 0\n",
    "regressor_error_relative = 0\n",
    "num_images = 0\n",
    "for image_path in tqdm.tqdm(image_paths):\n",
    "    image = imread(image_path, mode='RGB')\n",
    "\n",
    "    image_batch = data_to_input(image)\n",
    "\n",
    "    # Compute prediction with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, _ = predict.extract_cnn_output(outputs_np, cfg)\n",
    "\n",
    "    # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "    pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "    \n",
    "    mu = utils.predict_with_regressor(image, key_point_regressor)\n",
    "    \n",
    "    keypoint_path = utils.keypoint_path_from_cropped_image_path(image_path)\n",
    "    try:\n",
    "        with open(keypoint_path) as keypoint_file:\n",
    "            keypoints = json.load(keypoint_file)\n",
    "    except FileNotFoundError:\n",
    "        print(json_path)\n",
    "        continue\n",
    "    keypoints = np.array([[coords[0], coords[1]] for keypoint, coords in keypoints.items()])\n",
    "    deepercut_error_pixel += np.mean(np.linalg.norm(pose[:, :2] - keypoints, axis=1))\n",
    "    regressor_error_pixel += np.mean(np.linalg.norm(mu - keypoints, axis=1))\n",
    "    \n",
    "    keypoints = np.divide(keypoints, image.shape[:2])\n",
    "    pose = np.divide(pose[:, :2], image.shape[:2])\n",
    "    mu = np.divide(mu, image.shape[:2])\n",
    "    \n",
    "    deepercut_error_relative += np.mean(np.linalg.norm(pose - keypoints, axis=1))\n",
    "    regressor_error_relative += np.mean(np.linalg.norm(mu - keypoints, axis=1))\n",
    "    \n",
    "    num_images += 1\n",
    "    \n",
    "print('DeeperCut pixel:', deepercut_error_pixel / num_images)\n",
    "print('Regressor pixle:', regressor_error_pixel / num_images)\n",
    "print('DeeperCut relative:', deepercut_error_relative / num_images)\n",
    "print('Regressor relative:', regressor_error_relative / num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
